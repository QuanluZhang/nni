# Speedup Results

This code only works on torch 1.3.1 and torchvision 0.4.2

## slim pruner example

on one V100 GPU,
input tensor: `torch.randn(64, 3, 32, 32)`

|Times| Mask Latency| Speedup Latency |
|---|---|---|
| 1 | 0.011968851089477539 | 0.005106925964355469 |
| 2 | 0.020199298858642578 | 0.008769512176513672 |
| 4 | 0.027331113815307617 | 0.014809131622314453 |
| 8 | 0.043100595474243164 | 0.02744126319885254 |
| 16 | 0.07731318473815918 | 0.05007791519165039 |
| 32 | 0.14464616775512695 | 0.10027527809143066 |

## fpgm pruner example

on cpu,
input tensor: `torch.randn(64, 1, 28, 28)`,
too large variance

|Times| Mask Latency| Speedup Latency |
|---|---|---|
| 1 | 0.013831615447998047 | 0.018393278121948242 |
| 2 | 0.011675357818603516 | 0.0035581588745117188 |
| 4 | 0.016363859176635742 | 0.01088404655456543 |
| 40 | 0.14412355422973633 | 0.08268260955810547 |
| 40 | 1.2938556671142578 | 0.1440880298614502 |
| 40 | 0.4103574752807617 | 0.4616250991821289 |
| 400 | 6.290201425552368 | 5.821432113647461 |

## l1filter pruner example

on one V100 GPU,
input tensor: `torch.randn(64, 3, 32, 32)`

|Times| Mask Latency| Speedup Latency |
|---|---|---|
| 1 | 0.010260343551635742 | 0.0036773681640625 |
| 2 | 0.016577482223510742 | 0.008161306381225586 |
| 4 | 0.0245821475982666 | 0.02001810073852539 |
| 8 | 0.034986257553100586 | 0.025504589080810547 |
| 16 | 0.06757736206054688 | 0.04752326011657715 |
| 32 | 0.10487151145935059 | 0.08644247055053711 |

## APoZ pruner example

on one V100 GPU,
input tensor: `torch.randn(64, 3, 32, 32)`

|Times| Mask Latency| Speedup Latency |
|---|---|---|
| 1 | 0.013897180557250977 | 0.004208564758300781 |
| 2 | 0.016284465789794922 | 0.008310556411743164 |
| 4 | 0.02521061897277832 | 0.01400899887084961 |
| 8 | 0.03386855125427246 | 0.023923158645629883 |
| 16 | 0.060423851013183594 | 0.046183109283447266 |
| 32 | 0.12421965599060059 | 0.0871133804321289 |